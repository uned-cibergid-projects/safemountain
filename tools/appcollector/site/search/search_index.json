{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"AppCollector Documentation","text":""},{"location":"index.html#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"index.html#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml \ndocs/\n    index.md \n    dataCollectors/\n        getHostAppsList.md\n        getHostAppsMetadata.md\n        getTPLsDirectories.md\n        getTPLsMetadata.md\n        utils.md\n    downloaders/\n        getHostApks.md\n        getTpls.md\n        utils.md\n</code></pre>"},{"location":"fileSystemUtils.html","title":"fileSystemUtils.md","text":""},{"location":"fileSystemUtils.html#sources.fileSystemUtils.checkFolder","title":"<code>checkFolder(folderPath)</code>","text":"<p>Ensures that the specified folder exists. If the folder does not exist, it is created.</p> <p>This function utilizes <code>os.makedirs</code> with <code>exist_ok=True</code> to create the directory at the given path. If the directory already exists, no exception is raised, and the function completes silently.</p> <p>Parameters:</p> Name Type Description Default <code>folderPath</code> <code>str</code> <p>The path of the folder to check or create. This can be an absolute or relative path.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the directory cannot be created due to permission issues or invalid path.</p> Source code in <code>sources/fileSystemUtils.py</code> <pre><code>def checkFolder(folderPath):\n    \"\"\"\n    Ensures that the specified folder exists. If the folder does not exist, it is created.\n\n    This function utilizes `os.makedirs` with `exist_ok=True` to create the directory at the given\n    path. If the directory already exists, no exception is raised, and the function completes\n    silently.\n\n    :param folderPath: The path of the folder to check or create.\n                       This can be an absolute or relative path.\n    :type folderPath: str\n    :return: None\n    :raises OSError: If the directory cannot be created due to permission issues or invalid path.\n    \"\"\"\n    os.makedirs(folderPath, exist_ok=True)\n</code></pre>"},{"location":"logger.html","title":"logger.md","text":""},{"location":"logger.html#sources.logger.configureLogger","title":"<code>configureLogger(logFilePath, mode, loggerName)</code>","text":"<p>Configures a logger with both file and console handlers.</p> <p>This function sets up a logger with the specified name, directing log messages to both a file and the console. It ensures that multiple handlers are not added to the logger if it has already been configured.</p> <p>Parameters:</p> Name Type Description Default <code>logFilePath</code> <code>str</code> <p>The file path where the log messages will be stored. Example: \"../logs/apk.log\"</p> required <code>mode</code> <code>str</code> <p>The mode in which the log file is opened. - \"w\" for write mode (overwrites existing file) - \"a\" for append mode (adds to existing file)</p> required <code>loggerName</code> <code>str</code> <p>The name identifier for the logger. Example: \"logger\" or \"exceptionLogger\"</p> required <p>Returns:</p> Type Description <code>logging.Logger</code> <p>The configured logger instance.</p> Source code in <code>sources/logger.py</code> <pre><code>def configureLogger(logFilePath, mode, loggerName):\n    \"\"\"\n    Configures a logger with both file and console handlers.\n\n    This function sets up a logger with the specified name, directing log messages\n    to both a file and the console. It ensures that multiple handlers are not\n    added to the logger if it has already been configured.\n\n    :param logFilePath: The file path where the log messages will be stored.\n                        Example: \"../logs/apk.log\"\n    :type logFilePath: str\n    :param mode: The mode in which the log file is opened.\n                 - \"w\" for write mode (overwrites existing file)\n                 - \"a\" for append mode (adds to existing file)\n    :type mode: str\n    :param loggerName: The name identifier for the logger.\n                       Example: \"logger\" or \"exceptionLogger\"\n    :type loggerName: str\n    :return: The configured logger instance.\n    :rtype: logging.Logger\n    \"\"\"\n    logger = logging.getLogger(loggerName)\n\n    if not logger.hasHandlers():\n        logger.setLevel(logging.DEBUG)\n\n        fileHandler = logging.FileHandler(logFilePath, mode=mode)\n        fileHandler.setLevel(logging.DEBUG)\n\n        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n        fileHandler.setFormatter(formatter)\n\n        logger.addHandler(fileHandler)\n\n        console_handler = logging.StreamHandler()\n        console_handler.setFormatter(formatter)\n\n        logger.addHandler(console_handler)\n\n    return logger\n</code></pre>"},{"location":"logger.html#sources.logger.writeLog","title":"<code>writeLog(logType, logger, msg)</code>","text":"<p>Writes a log message to the specified logger based on the log type.</p> <p>This function simplifies logging by allowing the caller to specify the type of log message (e.g., info, warning, debug, error, exception) and directing the message to the appropriate logging method.</p> <p>Parameters:</p> Name Type Description Default <code>logType</code> <code>str</code> <p>The severity level of the log message. Accepted values: - \"info\" for informational messages - \"warning\" for warning messages - \"debug\" for debug-level messages - \"error\" for error messages - \"exception\" for exception tracebacks</p> required <code>logger</code> <code>logging.Logger</code> <p>The logger instance to which the message will be logged. This should be a logger configured using <code>configureLogger</code>.</p> required <code>msg</code> <code>str</code> <p>The log message to be recorded. This can be any string describing the event or error.</p> required Source code in <code>sources/logger.py</code> <pre><code>def writeLog(logType, logger, msg):\n    \"\"\"\n    Writes a log message to the specified logger based on the log type.\n\n    This function simplifies logging by allowing the caller to specify the\n    type of log message (e.g., info, warning, debug, error, exception) and\n    directing the message to the appropriate logging method.\n\n    :param logType: The severity level of the log message.\n                    Accepted values:\n                    - \"info\" for informational messages\n                    - \"warning\" for warning messages\n                    - \"debug\" for debug-level messages\n                    - \"error\" for error messages\n                    - \"exception\" for exception tracebacks\n    :type logType: str\n    :param logger: The logger instance to which the message will be logged.\n                   This should be a logger configured using `configureLogger`.\n    :type logger: logging.Logger\n    :param msg: The log message to be recorded.\n               This can be any string describing the event or error.\n    :type msg: str\n    \"\"\"\n    if logType == \"info\":\n        logger.info(msg)\n    elif logType == \"warning\":\n        logger.warning(msg)\n    elif logType == \"debug\":\n        logger.debug(msg)\n    elif logType == \"error\":\n        logger.error(msg)\n    elif logType == \"exception\":\n        logger.exception(msg)\n    else:\n        logger.error(\"Invalid log type specified: %s\", logType)\n</code></pre>"},{"location":"dataCollectors/getHostAppsList.html","title":"getHostAppsList","text":""},{"location":"dataCollectors/getHostAppsList.html#sources.dataCollectors.getHostAppsList.main","title":"<code>main()</code>","text":"<p>Main function to orchestrate the collection and storage of host applications data from AppBrain.</p> Source code in <code>sources/dataCollectors/getHostAppsList.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to orchestrate the collection and storage of host applications data from AppBrain.\n    \"\"\"\n    client = MongoClient('mongodb://10.201.54.162:49016')\n    db = client['metadata']\n    collection = db['apks']\n\n    logFilePath = \"../logs/hostAppsList.log\"\n    exceptionLogFilePath = \"../logs/hostAppsListException.log\"\n\n    configureLogger(logFilePath, \"w\", \"logger\")\n    configureLogger(exceptionLogFilePath, \"w\", \"exceptionLogger\")\n\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    saveFolder = \"../../results/hostAppsList/\"\n    checkFolder(saveFolder)\n\n    appbrain = \"https://www.appbrain.com\"\n    appCategories = [\"social\"]\n\n    for appCategory in appCategories:\n        processAppCategory(appCategory, saveFolder, appbrain, collection, logger, exceptionLogger)\n</code></pre>"},{"location":"dataCollectors/getHostAppsList.html#sources.dataCollectors.getHostAppsList.processAppCategory","title":"<code>processAppCategory(appCategory, saveFolder, appbrain, collection, logger, exceptionLogger)</code>","text":"<p>Processes a single application category by retrieving, filtering, and storing host applications.</p> <p>Parameters:</p> Name Type Description Default <code>appCategory</code> <code>str</code> <p>The category of applications to process.</p> required <code>saveFolder</code> <code>str</code> <p>Path to the folder where results are saved.</p> required <code>appbrain</code> <code>str</code> <p>Base URL of AppBrain.</p> required <code>collection</code> <code>pymongo.collection.Collection</code> <p>MongoDB collection to store host applications.</p> required <code>logger</code> <code>logging.Logger</code> <p>Logger for general logging.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exception logging.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of host apps added.</p> Source code in <code>sources/dataCollectors/getHostAppsList.py</code> <pre><code>def processAppCategory(appCategory, saveFolder, appbrain, collection, logger, exceptionLogger):\n    \"\"\"\n    Processes a single application category by retrieving, filtering, and storing host applications.\n\n    :param appCategory: The category of applications to process.\n    :type appCategory: str\n    :param saveFolder: Path to the folder where results are saved.\n    :type saveFolder: str\n    :param appbrain: Base URL of AppBrain.\n    :type appbrain: str\n    :param collection: MongoDB collection to store host applications.\n    :type collection: pymongo.collection.Collection\n    :param logger: Logger for general logging.\n    :type logger: logging.Logger\n    :param exceptionLogger: Logger for exception logging.\n    :type exceptionLogger: logging.Logger\n    :return: Number of host apps added.\n    :rtype: int\n    \"\"\"\n    saveFile = os.path.join(saveFolder, f\"{appCategory}.json\")\n\n    if os.path.exists(saveFile):\n        with open(saveFile, \"r\") as existingFile:\n            try:\n                hostAppsList = json.load(existingFile)\n            except json.JSONDecodeError:\n                hostAppsList = []\n    else:\n        hostAppsList = []\n\n    f = open(saveFile, \"w\")\n    appCategoryUrl = f'https://www.appbrain.com/apps/most-downloaded/{appCategory}'\n    pathUrls = getPathUrlsAppbrain(appCategoryUrl)\n    pathUrls = list(dict.fromkeys(pathUrls))  # Remove duplicates\n\n    hostAppsAdded = 0\n\n    for pathUrl in pathUrls:\n        try:\n            if \"/app/\" in pathUrl:\n                hostAppName, hostAppPackage = pathUrl.split(\"/\")[-2:]\n                hostAppLink = appbrain + pathUrl\n\n                writeLog(\"debug\", logger, f\"Host app name:    \\t{hostAppName}\")\n                writeLog(\"debug\", logger, f\"Host app package: \\t{hostAppPackage}\")\n                writeLog(\"debug\", logger, f\"Host app link:    \\t{hostAppLink}\")\n\n                existingApp = collection.find_one({\"package\": hostAppPackage})\n\n                if not existingApp:\n                    hostAppsAdded += 1\n                    hostApp = {\n                        \"name\": hostAppName,\n                        \"package\": hostAppPackage,\n                        \"category\": appCategory,\n                    }\n                    collection.insert_one(hostApp)\n                    hostAppsList.append(hostApp)\n\n                    writeLog(\"info\", logger, f\"Host app '{hostAppName}' added to the collection.\")\n                else:\n                    writeLog(\"info\", logger, f\"Host app '{hostAppName}' already exists in the collection.\")\n\n        except Exception as e:\n            writeLog(\"exception\", exceptionLogger, f\"Exception occurred: {e}\")\n\n    with open(saveFile, \"w\") as saveFileHandler:\n        reorderedHostAppsList = reorderListId(hostAppsList)\n        json.dump(reorderedHostAppsList, saveFileHandler, indent=4)\n\n    writeLog(\"debug\", logger, f\"Host apps' category:            {appCategory}\")\n    writeLog(\"debug\", logger, f\"Number of host apps added:       {hostAppsAdded}\")\n\n    return hostAppsAdded\n</code></pre>"},{"location":"dataCollectors/getHostAppsMetadata.html","title":"getHostAppsMetadata","text":""},{"location":"dataCollectors/getHostAppsMetadata.html#sources.dataCollectors.getHostAppsMetadata.addMetadata","title":"<code>addMetadata(document, apksCollection, versionsCollection, logger, exceptionLogger)</code>","text":"<p>Adds metadata to the MongoDB collections and updates JSON files with the retrieved metadata.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>dict</code> <p>The MongoDB document containing application details.</p> required <code>apksCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for APKs.</p> required <code>versionsCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for versions.</p> required <code>logger</code> <code>logging.Logger</code> <p>Logger for general logging.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exception logging.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>sources/dataCollectors/getHostAppsMetadata.py</code> <pre><code>def addMetadata(document, apksCollection, versionsCollection, logger, exceptionLogger):\n    \"\"\"\n    Adds metadata to the MongoDB collections and updates JSON files with the retrieved metadata.\n\n    :param document: The MongoDB document containing application details.\n    :type document: dict\n    :param apksCollection: The MongoDB collection for APKs.\n    :type apksCollection: pymongo.collection.Collection\n    :param versionsCollection: The MongoDB collection for versions.\n    :type versionsCollection: pymongo.collection.Collection\n    :param logger: Logger for general logging.\n    :type logger: logging.Logger\n    :param exceptionLogger: Logger for exception logging.\n    :type exceptionLogger: logging.Logger\n    :return: None\n    :rtype: None\n    \"\"\"\n    appMetadata, versionMetadata = getMetadata(document, exceptionLogger)\n\n    if appMetadata and versionMetadata:\n\n        apkSaveFolder = \"../../results/hostAppsList/\"\n        versionSaveFolder = \"../../results/versionsList/\"\n\n        # Update mongo with metadata.\n        apksCollection.update_one(\n            {\"_id\": document[\"_id\"]},\n            {\"$set\": appMetadata}\n        )\n\n        # Update json with metadata.\n        category = document.get(\"category\")\n        if category:\n            jsonFilePath = os.path.join(apkSaveFolder, f\"{category}.json\")\n            if os.path.exists(jsonFilePath):\n                with open(jsonFilePath, \"r+\", encoding=\"utf-8\") as jsonFile:\n                    try:\n                        apks = json.load(jsonFile)\n                    except json.JSONDecodeError as e:\n                        writeLog(\n                            \"exception\",\n                            exceptionLogger,\n                            f\"Error decoding the JSON file {category}.json: \\n{e}\"\n                        )\n                        apks = []\n\n                    for apk in apks:\n                        if apk.get(\"_id\") == str(document[\"_id\"]):\n                            apk.update(appMetadata)\n                            break\n\n                    jsonFile.seek(0)\n                    json.dump(apks, jsonFile, ensure_ascii=False, indent=4)\n                    jsonFile.truncate()\n\n        writeLog(\"info\", logger, \"Actualizada metadata de la APK\")\n\n        existingVersion = versionsCollection.find_one({\n            \"type\": versionMetadata[\"type\"],\n            \"parentId\": document[\"_id\"],\n            \"versionCode\": versionMetadata[\"versionCode\"]\n        })\n\n        if not existingVersion:\n\n            # Update mongo with metadata.\n            versionsCollection.insert_one(versionMetadata)\n            writeLog(\n                \"info\",\n                logger,\n                f\"Se ha actualizado la versi\u00f3n {versionMetadata['versionCode']} de la \"\n                f\"APK de name: {document['name']} y package {document['package']}\"\n            )\n\n            # Update json with metadata.\n            typeSaveFolder = os.path.join(versionSaveFolder, f\"{versionMetadata['type']}\")\n            packageSaveFolder = os.path.join(typeSaveFolder, f\"{document['package']}\")\n            saveFile = os.path.join(packageSaveFolder, f\"{document['name']}.json\")\n\n            os.makedirs(typeSaveFolder, exist_ok=True)\n            os.makedirs(packageSaveFolder, exist_ok=True)\n\n            if os.path.exists(saveFile):\n                with open(saveFile, \"r\") as existingFile:\n                    try:\n                        versionsList = json.load(existingFile)\n                    except json.JSONDecodeError:\n                        versionsList = []\n            else:\n                versionsList = []\n\n            versionExists = False\n            for version in versionsList:\n                if version.get(\"versionCode\") == versionMetadata[\"versionCode\"]:\n                    versionExists = True\n                    break\n\n            if not versionExists:\n                if isinstance(versionMetadata.get(\"_id\"), ObjectId):\n                    newVersion = {\n                        \"_id\": str(versionMetadata[\"_id\"]),\n                        \"parentId\": str(document[\"_id\"]),\n                        \"type\": versionMetadata[\"type\"],\n                        \"versionCode\": versionMetadata[\"versionCode\"],\n                        \"releaseDate\": versionMetadata[\"releaseDate\"]\n                    }\n                    versionsList.append(newVersion)\n\n            with open(saveFile, \"w\", encoding=\"utf-8\") as jsonFile:\n                json.dump(versionsList, jsonFile, ensure_ascii=False, indent=4)\n\n        else:\n            writeLog(\n                \"info\",\n                logger,\n                \"La metadata de la \u00faltima versi\u00f3n de la APK ya estaba registrada en Mongo\"\n            )\n</code></pre>"},{"location":"dataCollectors/getHostAppsMetadata.html#sources.dataCollectors.getHostAppsMetadata.getMetadata","title":"<code>getMetadata(document, exceptionLogger)</code>","text":"<p>Retrieves metadata for a given application from the Google Play Store.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>dict</code> <p>The MongoDB document containing application details.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exception logging.</p> required <p>Returns:</p> Type Description <code>tuple (dict, dict)</code> <p>A tuple containing application metadata and version metadata.</p> Source code in <code>sources/dataCollectors/getHostAppsMetadata.py</code> <pre><code>def getMetadata(document, exceptionLogger):\n    \"\"\"\n    Retrieves metadata for a given application from the Google Play Store.\n\n    :param document: The MongoDB document containing application details.\n    :type document: dict\n    :param exceptionLogger: Logger for exception logging.\n    :type exceptionLogger: logging.Logger\n    :return: A tuple containing application metadata and version metadata.\n    :rtype: tuple (dict, dict)\n    \"\"\"\n    apkId = document.get(\"_id\")\n    package = document.get(\"package\")\n\n    try:\n        resultGooglePlayScraper = app(package)\n\n        appMetadata = {\n            'title': resultGooglePlayScraper['title'],\n            'description': resultGooglePlayScraper['description'],\n            'installs': resultGooglePlayScraper['installs'],\n            'realInstalls': resultGooglePlayScraper['realInstalls'],\n            'score': resultGooglePlayScraper['score'],\n            'ratings': resultGooglePlayScraper['ratings'],\n            'reviews': resultGooglePlayScraper['reviews'],\n            'histogram': resultGooglePlayScraper['histogram'],\n            'price': resultGooglePlayScraper['price'],\n            'free': resultGooglePlayScraper['free'],\n            'currency': resultGooglePlayScraper['currency'],\n            'developer': resultGooglePlayScraper['developer'],\n            'developerEmail': resultGooglePlayScraper['developerEmail'],\n            'developerWebsiteUrl': resultGooglePlayScraper['developerWebsite'],\n            'privacyPolicyUrl': resultGooglePlayScraper['privacyPolicy'],\n            'genre': resultGooglePlayScraper['genre'],\n            'genreId': resultGooglePlayScraper['genreId'],\n            'iconUrl': resultGooglePlayScraper['icon'],\n            'headerImageUrl': resultGooglePlayScraper['headerImage'],\n            'screenshotsUrls': resultGooglePlayScraper['screenshots'],\n            'videoUrl': resultGooglePlayScraper['video'],\n            'videoImageUrl': resultGooglePlayScraper['videoImage'],\n            'contentRating': resultGooglePlayScraper['contentRating'],\n            'contentRatingDescription': resultGooglePlayScraper['contentRatingDescription'],\n            'adSupported': resultGooglePlayScraper['adSupported'],\n            'containsAds': resultGooglePlayScraper['containsAds'],\n            'released': resultGooglePlayScraper['released'],\n            'googlePlayUrl': f'https://play.google.com/store/apps/details?id={package}',\n        }\n\n        versionMetadata = {\n            'parentId': apkId,\n            'type': 'apk',\n            'versionCode': resultGooglePlayScraper['version'],\n            'releaseDate': resultGooglePlayScraper['lastUpdatedOn'],\n        }\n\n        return appMetadata, versionMetadata\n\n    except Exception as e:\n        writeLog(\n            \"exception\",\n            exceptionLogger,\n            f\"Exception occurred: \\n{e}\\n\"\n            f\"The requested URL was not found on Google Play Store server\\n\"\n            f\"Id: {document['_id']}\\n\"\n            f\"Name: {document['name']}\\n\"\n            f\"Package: {document['package']}\"\n        )\n\n        return {}, {}\n</code></pre>"},{"location":"dataCollectors/getHostAppsMetadata.html#sources.dataCollectors.getHostAppsMetadata.getMetadataGooglePlay","title":"<code>getMetadataGooglePlay(apksCollection, versionsCollection, logger, exceptionLogger)</code>","text":"<p>Retrieves and processes metadata for all applications in the APKs collection from Google Play Store.</p> <p>Parameters:</p> Name Type Description Default <code>apksCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for APKs.</p> required <code>versionsCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for versions.</p> required <code>logger</code> <code>logging.Logger</code> <p>Logger for general logging.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exception logging.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>sources/dataCollectors/getHostAppsMetadata.py</code> <pre><code>def getMetadataGooglePlay(apksCollection, versionsCollection, logger, exceptionLogger):\n    \"\"\"\n    Retrieves and processes metadata for all applications in the APKs collection from Google Play Store.\n\n    :param apksCollection: The MongoDB collection for APKs.\n    :type apksCollection: pymongo.collection.Collection\n    :param versionsCollection: The MongoDB collection for versions.\n    :type versionsCollection: pymongo.collection.Collection\n    :param logger: Logger for general logging.\n    :type logger: logging.Logger\n    :param exceptionLogger: Logger for exception logging.\n    :type exceptionLogger: logging.Logger\n    :return: None\n    :rtype: None\n    \"\"\"\n    documents = apksCollection.find({})\n\n    for document in documents:\n        writeLog(\"info\", logger, \"Processing app:\")\n        writeLog(\"info\", logger, f\"Id: {document['_id']}\")\n        writeLog(\"info\", logger, f\"Name: {document['name']}\")\n        writeLog(\"info\", logger, f\"Package: {document['package']}\")\n\n        addMetadata(document, apksCollection, versionsCollection, logger, exceptionLogger)\n</code></pre>"},{"location":"dataCollectors/getHostAppsMetadata.html#sources.dataCollectors.getHostAppsMetadata.main","title":"<code>main()</code>","text":"<p>Main function to orchestrate the metadata collection process.</p> Source code in <code>sources/dataCollectors/getHostAppsMetadata.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to orchestrate the metadata collection process.\n    \"\"\"\n    client = MongoClient('mongodb://10.201.54.162:49016')\n    db = client['metadata']\n    apksCollection = db['apks']\n    versionsCollection = db['versions']\n\n    logFilePath = \"../logs/hostAppsMetadata.log\"\n    exceptionLogFilePath = \"../logs/hostAppsMetadataException.log\"\n\n    configureLogger(logFilePath, \"w\", \"logger\")\n    configureLogger(exceptionLogFilePath, \"w\", \"exceptionLogger\")\n\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    writeLog(\"info\", logger, \"Iniciando proceso de recolecci\u00f3n de metadata de APKs\")\n\n    getMetadataGooglePlay(apksCollection, versionsCollection, logger, exceptionLogger)\n</code></pre>"},{"location":"dataCollectors/getTPLsDirectories.html","title":"getTPLsDirectories","text":""},{"location":"dataCollectors/getTPLsDirectories.html#sources.dataCollectors.getTPLsDirectories.getDirectoryUrls","title":"<code>getDirectoryUrls(urls)</code>","text":"<p>Filters and returns URLs that represent valid directories.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list</code> <p>List of URLs obtained from the Maven repository.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of URLs that end with '/' and do not start with '..'.</p> Source code in <code>sources/dataCollectors/getTPLsDirectories.py</code> <pre><code>def getDirectoryUrls(urls):\n    \"\"\"\n    Filters and returns URLs that represent valid directories.\n\n    :param urls: List of URLs obtained from the Maven repository.\n    :type urls: list\n    :return: List of URLs that end with '/' and do not start with '..'.\n    :rtype: list\n    \"\"\"\n    directoryUrls = []\n    for url in urls:\n        if url.endswith('/') and not url.startswith('..'):\n            directoryUrls.append(url)\n    return directoryUrls\n</code></pre>"},{"location":"dataCollectors/getTPLsDirectories.html#sources.dataCollectors.getTPLsDirectories.getTPLsDirectories","title":"<code>getTPLsDirectories()</code>","text":"<p>Retrieves the complete URLs of TPL directories from the Maven repository.</p> <p>Returns:</p> Type Description <code>list</code> <p>List of complete URLs of TPL directories.</p> Source code in <code>sources/dataCollectors/getTPLsDirectories.py</code> <pre><code>def getTPLsDirectories():\n    \"\"\"\n    Retrieves the complete URLs of TPL directories from the Maven repository.\n\n    :return: List of complete URLs of TPL directories.\n    :rtype: list\n    \"\"\"\n    urls = getHrefs(MAVEN_REPO_URL)\n    directoryUrls = getDirectoryUrls(urls)\n    tplsDirectories = [MAVEN_REPO_URL + directoryUrl for directoryUrl in directoryUrls]\n    return tplsDirectories\n</code></pre>"},{"location":"dataCollectors/getTPLsDirectories.html#sources.dataCollectors.getTPLsDirectories.main","title":"<code>main()</code>","text":"<p>Main function to orchestrate the collection and storage of TPL directory metadata.</p> Source code in <code>sources/dataCollectors/getTPLsDirectories.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to orchestrate the collection and storage of TPL directory metadata.\n    \"\"\"\n\n    try:\n        client = MongoClient('mongodb://10.201.54.162:49016')\n        db = client['metadata']\n        collection = db['tplDirectories']\n\n        logFilePath = \"../logs/tplDirectories.log\"\n        exceptionLogFilePath = \"../logs/tplDirectoriesException.log\"\n\n        configureLogger(logFilePath, \"w\", \"logger\")\n        configureLogger(exceptionLogFilePath, \"w\", \"exceptionLogger\")\n\n        logger = logging.getLogger(\"logger\")\n        exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n        saveFolder = \"../../results/tplDirectories/\"\n        checkFolder(saveFolder)\n\n        tplsDirectories = getTPLsDirectories()\n\n        saveFile = os.path.join(saveFolder, f\"{MAVEN_REPO_NAME}.json\")\n        if os.path.exists(saveFile):\n            with open(saveFile, \"r\") as existingFile:\n                try:\n                    tplDirectoryList = json.load(existingFile)\n                except json.JSONDecodeError:\n                    tplDirectoryList = []\n        else:\n            tplDirectoryList = []\n\n        for tplDirectory in tplsDirectories:\n            try:\n                writeLog(\"debug\", logger, \"TPL Directory:    \\t\" + tplDirectory)\n\n                existingDirectory = collection.find_one({\"url\": tplDirectory})\n\n                if not existingDirectory:\n                    tplDirectoryAdded = {\"url\": tplDirectory}\n                    collection.insert_one(tplDirectoryAdded)\n                    tplDirectoryList.append(tplDirectoryAdded)\n\n                    writeLog(\"info\", logger, f\"TPL directory '{tplDirectory}' added to the collection.\")\n                else:\n                    writeLog(\"info\", logger, f\"TPL directory '{tplDirectory}' already exists in the collection.\")\n\n            except Exception as e:\n                writeLog(\"exception\", exceptionLogger, f\"Exception occurred: {e}\")\n\n        with open(saveFile, \"w\") as saveFileHandler:\n            reorderedTplDirectoryList = reorderListId(tplDirectoryList)\n            json.dump(reorderedTplDirectoryList, saveFileHandler, indent=4)\n\n    except Exception as e:\n        writeLog(\"exception\", exceptionLogger, f\"An error occurred in the main function: {e}\")\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html","title":"getTPLsMetadata","text":""},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.extractJarFileUrlMetadata","title":"<code>extractJarFileUrlMetadata(url)</code>","text":"<p>Extracts metadata from the jar file URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the jar file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with 'name', 'package', and 'version'.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>def extractJarFileUrlMetadata(url):\n    \"\"\"\n    Extracts metadata from the jar file URL.\n\n    :param url: URL of the jar file.\n    :type url: str\n    :return: Dictionary with 'name', 'package', and 'version'.\n    :rtype: dict\n    \"\"\"\n    pattern = r\"https://repo\\.maven\\.apache\\.org/maven2/((?:[^/]+/)+)([^/]+)/([^/]+)/.*\\.(jar|aar)\"\n    match = re.match(pattern, url)\n\n    if match:\n        packageParts = match.group(1).strip('/').split('/')\n        package = '.'.join(packageParts)\n        name = match.group(2)\n        version = match.group(3)\n        return {\n            \"name\": name,\n            \"package\": package,\n            \"version\": version\n        }\n    else:\n        return {}\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.filterSignificantVersionsMetadata","title":"<code>filterSignificantVersionsMetadata(jarFilesUrls, tplsCollection, versionsCollection)</code>  <code>async</code>","text":"<p>Filters significant versions from the list of jar file URLs and updates the database.</p> <p>Parameters:</p> Name Type Description Default <code>jarFilesUrls</code> <code>list of str</code> <p>List of jar file URLs.</p> required <code>tplsCollection</code> <code>pymongo.collection.Collection</code> <p>MongoDB collection for TPLs.</p> required <code>versionsCollection</code> <code>pymongo.collection.Collection</code> <p>MongoDB collection for versions.</p> required <p>Returns:</p> Type Description <code>list of dict</code> <p>List of significant versions metadata.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def filterSignificantVersionsMetadata(jarFilesUrls, tplsCollection, versionsCollection):\n    \"\"\"\n    Filters significant versions from the list of jar file URLs and updates the database.\n\n    :param jarFilesUrls: List of jar file URLs.\n    :type jarFilesUrls: list of str\n    :param tplsCollection: MongoDB collection for TPLs.\n    :type tplsCollection: pymongo.collection.Collection\n    :param versionsCollection: MongoDB collection for versions.\n    :type versionsCollection: pymongo.collection.Collection\n    :return: List of significant versions metadata.\n    :rtype: list of dict\n    \"\"\"\n    significantVersionsMetadata = []\n    semaphore = asyncio.Semaphore(10)\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    try:\n        for jarFileUrl in jarFilesUrls:\n            jarFileUrlMetadata = extractJarFileUrlMetadata(jarFileUrl)\n            if not jarFileUrlMetadata:\n                continue\n\n            name = jarFileUrlMetadata['name']\n            package = jarFileUrlMetadata[\"package\"]\n            newVersion = jarFileUrlMetadata[\"version\"]\n\n            if not isValidVersion(newVersion):\n                writeLog(\"exception\", exceptionLogger, f\"Invalid newVersion format: {newVersion}\")\n                continue\n\n            existingTpl = tplsCollection.find_one({\"name\": name, \"package\": package})\n\n            if existingTpl:\n                existingVersions = versionsCollection.find({\"parentId\": existingTpl[\"_id\"]})\n                existingVersionsList = [v[\"versionCode\"] for v in existingVersions if isValidVersion(v[\"versionCode\"])]\n\n                isSignificant = await isSignificantVersion(newVersion, existingVersionsList, semaphore, exceptionLogger)\n\n                if isSignificant:\n                    newSignificantVersion = {\n                        \"parentId\": existingTpl[\"_id\"],\n                        \"type\": \"tpl\",\n                        \"versionCode\": newVersion,\n                        \"downloadUrl\": jarFileUrl\n                    }\n\n                    # Update MongoDB with metadata.\n                    versionsCollection.insert_one(newSignificantVersion)\n\n                    newSignificantVersion[\"name\"] = name\n                    newSignificantVersion[\"package\"] = package\n                    significantVersionsMetadata.append(newSignificantVersion)\n            else:\n\n                newTpl = {\n                    \"name\": name,\n                    \"package\": package\n                }\n                tplsCollection.insert_one(newTpl)\n                createdTpl = tplsCollection.find_one({\"name\": name, \"package\": package})\n\n                newSignificantVersion = {\n                    \"parentId\": createdTpl[\"_id\"],\n                    \"type\": \"tpl\",\n                    \"versionCode\": newVersion,\n                    \"downloadUrl\": jarFileUrl\n                }\n\n                versionsCollection.insert_one(newSignificantVersion)\n\n                newSignificantVersion[\"name\"] = name\n                newSignificantVersion[\"package\"] = package\n                significantVersionsMetadata.append(newSignificantVersion)\n\n        return significantVersionsMetadata\n    except Exception as e:\n        writeLog(\"exception\", exceptionLogger, f\"Error while filtering significant versions metadata: {e}\")\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.getJarFilesUrls","title":"<code>getJarFilesUrls(tplDirectoriesCollection, saveFolder)</code>  <code>async</code>","text":"<p>Retrieves jar file URLs from TPL directories that need to be processed.</p> <p>Parameters:</p> Name Type Description Default <code>tplDirectoriesCollection</code> <code>pymongo.collection.Collection</code> <p>MongoDB collection of TPL directories.</p> required <code>saveFolder</code> <code>str</code> <p>Path to the folder where results are saved.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of jar file URLs.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def getJarFilesUrls(tplDirectoriesCollection, saveFolder):\n    \"\"\"\n    Retrieves jar file URLs from TPL directories that need to be processed.\n\n    :param tplDirectoriesCollection: MongoDB collection of TPL directories.\n    :type tplDirectoriesCollection: pymongo.collection.Collection\n    :param saveFolder: Path to the folder where results are saved.\n    :type saveFolder: str\n    :return: List of jar file URLs.\n    :rtype: list\n    \"\"\"\n    jarFilesUrls = []\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n    currentTime = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n\n    twoWeeksAgo = (datetime.now(timezone.utc) - timedelta(weeks=2)).strftime(\"%Y%m%d\")\n\n    document = tplDirectoriesCollection.find_one({\n        \"$or\": [\n            {\"lastTimeChecked\": {\"$exists\": False}},\n            {\"lastTimeChecked\": {\"$lt\": twoWeeksAgo}}\n        ]\n    })\n\n    if document:\n        lastTimeChecked = document.get(\"lastTimeChecked\", None)\n        writeLog(\"info\", logger, \"Processing TPL Directory:\")\n\n        writeLog(\"info\", logger, f\"Id: {str(document['_id'])}\")\n        writeLog(\"info\", logger, f\"Url: {document['url']}\")\n        writeLog(\"info\", logger, f\"Last time checked: {lastTimeChecked}\")\n        writeLog(\"info\", logger, f\"Current time: {currentTime}\")\n\n        directoryUrl = document[\"url\"]\n\n        semaphore = asyncio.Semaphore(40)\n\n        jarFilesUrls = await searchJarFilesUrls(directoryUrl, jarFilesUrls, semaphore)\n\n        # Update MongoDB with metadata.\n        tplDirectoriesCollection.update_one(\n            {\"_id\": document[\"_id\"]},\n            {\"$set\": {\"lastTimeChecked\": currentTime}},\n        )\n\n        # Update JSON with metadata.\n        jsonFilePath = os.path.join(saveFolder, f\"{MAVEN_REPO_NAME}.json\")\n        if os.path.exists(jsonFilePath):\n            with open(jsonFilePath, \"r+\", encoding=\"utf-8\") as jsonFile:\n                try:\n                    tplDirectories = json.load(jsonFile)\n                except json.JSONDecodeError as e:\n                    writeLog(\"exception\", exceptionLogger,\n                             f\"Error decoding the JSON file {MAVEN_REPO_NAME}.json: \\n{e}\")\n                    tplDirectories = []\n\n                for tplDirectory in tplDirectories:\n                    if tplDirectory.get(\"_id\") == str(document[\"_id\"]):\n                        tplDirectory.update({\"lastTimeChecked\": currentTime})\n                        break\n\n                jsonFile.seek(0)\n                json.dump(tplDirectories, jsonFile, ensure_ascii=False, indent=4)\n                jsonFile.truncate()\n\n        writeLog(\"info\", logger, f\"Updated TPL directory last check time: {document['url']}\")\n    else:\n        writeLog(\"info\", logger, \"There are no more TPL directories to process.\")\n\n    return jarFilesUrls\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.getTplMetadata","title":"<code>getTplMetadata(uniqueTpls, tplsCollection)</code>  <code>async</code>","text":"<p>Extracts metadata for each unique TPL from the Maven Central Repository and updates the <code>tplsCollection</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uniqueTpls</code> <code>list of dict</code> <p>List of unique TPLs to process.</p> required <code>tplsCollection</code> <code>pymongo.collection.Collection</code> <p>MongoDB collection where TPL metadata is stored.</p> required Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def getTplMetadata(uniqueTpls, tplsCollection):\n    \"\"\"\n    Extracts metadata for each unique TPL from the Maven Central Repository and updates the `tplsCollection`.\n\n    :param uniqueTpls: List of unique TPLs to process.\n    :type uniqueTpls: list of dict\n    :param tplsCollection: MongoDB collection where TPL metadata is stored.\n    :type tplsCollection: pymongo.collection.Collection\n    \"\"\"\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n    semaphore = asyncio.Semaphore(10)  # Limit the number of concurrent tasks\n\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True)\n\n        async def processUniqueTpl(uniqueTpl):\n            \"\"\"\n            Processes a single TPL to extract and update its metadata.\n\n            :param uniqueTpl: A dictionary containing 'name' and 'package' of the TPL.\n            :type uniqueTpl: dict\n            \"\"\"\n            async with semaphore:\n                currentTime = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n                name = uniqueTpl[\"name\"]\n                package = uniqueTpl[\"package\"]\n                mavenCentralRepositoryUrl = f\"https://central.sonatype.com/artifact/{package}/{name}\"\n\n                existingTpl = tplsCollection.find_one({\"name\": name, \"package\": package})\n\n                if existingTpl and \"lastTimeChecked\" in existingTpl:\n                    lastTimeChecked = existingTpl[\"lastTimeChecked\"]\n\n                    lastTimeCheckedDatetime = datetime.strptime(lastTimeChecked, \"%Y%m%d\").replace(tzinfo=timezone.utc)\n                    currentTimeDatetime = datetime.strptime(currentTime, \"%Y%m%d\").replace(tzinfo=timezone.utc)\n\n                    timeDifference = currentTimeDatetime - lastTimeCheckedDatetime\n\n                    mustBeChecked = timeDifference &gt;= timedelta(weeks=2)\n                else:\n                    mustBeChecked = True\n\n                if mustBeChecked:\n                    try:\n                        writeLog(\"info\", logger, f\"Surfing Maven Central Repository: {mavenCentralRepositoryUrl}\")\n                        page = await browser.new_page()\n                        await page.goto(mavenCentralRepositoryUrl, timeout=300000)\n                        content = await page.content()\n                        soup = BeautifulSoup(content, \"html.parser\")\n                        overviewDiv = soup.find(\"div\", {\"data-test\": \"overview\"})\n                        pomFilePre = soup.find(\"pre\", {\"data-test\": \"pom-file\"})\n                        ossindexMetadataVulnerabilitiesSpan = soup.find(\"span\", {\"data-test\": \"ossindex-metadata-vulnerabilities\"})\n                        publishedMetadataDiv = soup.find(\"div\", {\"data-test\": \"published-metadata\"})\n                        licensesLi = soup.find_all(\"li\", {\"data-test\": \"license\"})\n                        sizeMetadataDiv = soup.find(\"div\", {\"data-test\": \"size-metadata\"})\n                        projectUrlAnchor = soup.find(\"a\", {\"data-test\": \"project-url\"})\n                        issueManagementUrlAnchor = soup.find(\"a\", {\"data-test\": \"issue-management-url\"})\n                        scmUrlAnchor = soup.find(\"a\", {\"data-test\": \"scm-url\"})\n                        ciManagementAnchor = soup.find(\"a\", {\"data-test\": \"ci-management-url\"})\n\n                        newMetadata = {\n                            \"descripcion\": overviewDiv.get_text(strip=True) if overviewDiv else None,\n                            \"pomFile\": pomFilePre.get_text(strip=True) if pomFilePre else None,\n                            \"ossindexVulnerabilities\": ossindexMetadataVulnerabilitiesSpan.get_text(strip=True) if ossindexMetadataVulnerabilitiesSpan else None,\n                            \"published\": publishedMetadataDiv.get_text(strip=True) if publishedMetadataDiv else None,\n                            \"licenses\": [licenseLi.get_text(strip=True) for licenseLi in licensesLi] if licensesLi else [],\n                            \"size\": sizeMetadataDiv.get_text(strip=True) if sizeMetadataDiv else None,\n                            \"projectUrl\": projectUrlAnchor['href'] if projectUrlAnchor else None,\n                            \"issueTrackerUrl\": issueManagementUrlAnchor['href'] if issueManagementUrlAnchor else None,\n                            \"sourceControlUrl\": scmUrlAnchor['href'] if scmUrlAnchor else None,\n                            \"continuousIntegrationUrl\": ciManagementAnchor['href'] if ciManagementAnchor else None,\n                            \"lastTimeChecked\": currentTime\n                        }\n\n                        # Update MongoDB with metadata.\n                        tplsCollection.update_one(\n                            {\"name\": name, \"package\": package},\n                            {\"$set\": newMetadata}\n                        )\n                    except Exception as e:\n                        writeLog(\"exception\", exceptionLogger, f\"Error fetching metadata from Central Maven Repository for {name}: {e}\")\n                    finally:\n                        await page.close()\n                else:\n                    writeLog(\"info\", logger, f\"TPL has already been checked: {mavenCentralRepositoryUrl}\")\n\n        # Create asynchronous tasks for each TPL\n        tasks = [processUniqueTpl(uniqueTpl) for uniqueTpl in uniqueTpls]\n\n        # Execute tasks concurrently\n        await asyncio.gather(*tasks)\n\n        await browser.close()\n    return\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.getUniqueTpls","title":"<code>getUniqueTpls(significantVersionsMetadata)</code>  <code>async</code>","text":"<p>Obtains a list of unique TPLs from significant versions metadata.</p> <p>Parameters:</p> Name Type Description Default <code>significantVersionsMetadata</code> <code>list of dict</code> <p>List of significant versions metadata.</p> required <p>Returns:</p> Type Description <code>list of dict</code> <p>List of unique TPLs.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def getUniqueTpls(significantVersionsMetadata):\n    \"\"\"\n    Obtains a list of unique TPLs from significant versions metadata.\n\n    :param significantVersionsMetadata: List of significant versions metadata.\n    :type significantVersionsMetadata: list of dict\n    :return: List of unique TPLs.\n    :rtype: list of dict\n    \"\"\"\n    uniqueCombinations = set()\n    uniqueList = []\n\n    for doc in significantVersionsMetadata:\n        name = doc[\"name\"]\n        package = doc[\"package\"]\n        if (name, package) not in uniqueCombinations:\n            uniqueCombinations.add((name, package))\n            uniqueList.append({\"name\": name, \"package\": package})\n\n    return uniqueList\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.isSignificantVersion","title":"<code>isSignificantVersion(newVersion, existingVersionsList, semaphore, exceptionLogger)</code>  <code>async</code>","text":"<p>Determines if the new version is significant by comparing its major version with the existing major versions.</p> <p>Parameters:</p> Name Type Description Default <code>newVersion</code> <code>str</code> <p>The new version to compare.</p> required <code>existingVersionsList</code> <code>list of str</code> <p>List of existing version codes.</p> required <code>semaphore</code> <code>asyncio.Semaphore</code> <p>Semaphore to limit concurrency.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exceptions.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the version is significant, False otherwise.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def isSignificantVersion(newVersion, existingVersionsList, semaphore, exceptionLogger):\n    \"\"\"\n    Determines if the new version is significant by comparing its major version with the existing major versions.\n\n    :param newVersion: The new version to compare.\n    :type newVersion: str\n    :param existingVersionsList: List of existing version codes.\n    :type existingVersionsList: list of str\n    :param semaphore: Semaphore to limit concurrency.\n    :type semaphore: asyncio.Semaphore\n    :param exceptionLogger: Logger for exceptions.\n    :type exceptionLogger: logging.Logger\n    :return: True if the version is significant, False otherwise.\n    :rtype: bool\n    \"\"\"\n    try:\n        newVersionParsed = version.parse(newVersion)\n        if not isinstance(newVersionParsed, version.Version):\n            return False\n    except Exception as e:\n        writeLog(\"exception\", exceptionLogger, f\"Error parsing newVersion: {newVersion}, {e}\")\n        return False\n\n    newMajorVersion = newVersionParsed.major\n\n    existingMajorVersions = []\n    for existingVersion in existingVersionsList:\n        try:\n            existingVersionParsed = version.parse(existingVersion)\n            if isinstance(existingVersionParsed, version.Version):\n                existingMajorVersions.append(existingVersionParsed.major)\n        except Exception as e:\n            writeLog(\"exception\", exceptionLogger, f\"Error parsing existingVersion: {existingVersion}, {e}\")\n            continue\n\n    if not existingMajorVersions:\n        return True\n\n    maxExistingMajorVersion = max(existingMajorVersions)\n    if newMajorVersion &gt; maxExistingMajorVersion:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.isTplFile","title":"<code>isTplFile(url)</code>","text":"<p>Checks if the URL corresponds to a valid TPL file (excluding javadoc, tests, sources).</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if it is a valid TPL file, False otherwise.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>def isTplFile(url):\n    \"\"\"\n    Checks if the URL corresponds to a valid TPL file (excluding javadoc, tests, sources).\n\n    :param url: URL to check.\n    :type url: str\n    :return: True if it is a valid TPL file, False otherwise.\n    :rtype: bool\n    \"\"\"\n    pattern = r\"^(?!.*(javadoc|tests|sources)).*$\"\n    return re.search(pattern, url) is not None\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.isValidVersion","title":"<code>isValidVersion(versionStr)</code>","text":"<p>Checks if the version string is a valid version.</p> <p>Parameters:</p> Name Type Description Default <code>versionStr</code> <code>str</code> <p>Version string to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if it is a valid version, False otherwise.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>def isValidVersion(versionStr):\n    \"\"\"\n    Checks if the version string is a valid version.\n\n    :param versionStr: Version string to check.\n    :type versionStr: str\n    :return: True if it is a valid version, False otherwise.\n    :rtype: bool\n    \"\"\"\n    try:\n        version.parse(versionStr)\n        return True\n    except:\n        return False\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.main","title":"<code>main()</code>  <code>async</code>","text":"<p>Main function to orchestrate the metadata collection process.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def main():\n    \"\"\"\n    Main function to orchestrate the metadata collection process.\n    \"\"\"\n    client = MongoClient('mongodb://10.201.54.162:49016')\n    db = client['metadata']\n    tplDirectoriesCollection = db['tplDirectories']\n    tplsCollection = db['tpls']\n    versionsCollection = db['versions']\n\n    logFilePath = \"../logs/tplsMetadata.log\"\n    exceptionLogFilePath = \"../logs/tplsMetadataException.log\"\n\n    configureLogger(logFilePath, \"w\", \"logger\")\n    configureLogger(exceptionLogFilePath, \"w\", \"exceptionLogger\")\n\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    saveFolder = \"../../results/tplDirectories/\"\n    checkFolder(saveFolder)\n\n    versionSaveFolder = \"../../results/versionsList/\"\n    checkFolder(versionSaveFolder)\n\n    writeLog(\"info\", logger, \"Starting TPL metadata collection process\")\n\n    jarFilesUrls = await getJarFilesUrls(tplDirectoriesCollection, saveFolder)\n\n    if jarFilesUrls:\n        significantVersionsMetadata = await filterSignificantVersionsMetadata(jarFilesUrls, tplsCollection, versionsCollection)\n        uniqueTpls = await getUniqueTpls(significantVersionsMetadata)\n        await getTplMetadata(uniqueTpls, tplsCollection)\n    else:\n        writeLog(\"info\", logger, \"No jarFilesUrls were found to process.\")\n</code></pre>"},{"location":"dataCollectors/getTPLsMetadata.html#sources.dataCollectors.getTPLsMetadata.searchJarFilesUrls","title":"<code>searchJarFilesUrls(directoryUrl, jarFilesUrls, semaphore)</code>  <code>async</code>","text":"<p>Searches for jar file URLs starting from the given directory URL.</p> <p>Parameters:</p> Name Type Description Default <code>directoryUrl</code> <code>str</code> <p>Starting directory URL.</p> required <code>jarFilesUrls</code> <code>list</code> <p>List to store found jar file URLs.</p> required <code>semaphore</code> <code>asyncio.Semaphore</code> <p>Semaphore to limit concurrency.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of jar file URLs.</p> Source code in <code>sources/dataCollectors/getTPLsMetadata.py</code> <pre><code>async def searchJarFilesUrls(directoryUrl, jarFilesUrls, semaphore):\n    \"\"\"\n    Searches for jar file URLs starting from the given directory URL.\n\n    :param directoryUrl: Starting directory URL.\n    :type directoryUrl: str\n    :param jarFilesUrls: List to store found jar file URLs.\n    :type jarFilesUrls: list\n    :param semaphore: Semaphore to limit concurrency.\n    :type semaphore: asyncio.Semaphore\n    :return: List of jar file URLs.\n    :rtype: list\n    \"\"\"\n    queue = [directoryUrl]\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True)\n\n        while queue:\n            currentUrl = queue.pop(0)\n            async with semaphore:\n                page = await browser.new_page()\n                try:\n                    await page.goto(currentUrl)\n                    writeLog(\"info\", logger, f\"Surfing directory: {currentUrl}\")\n                    await page.wait_for_selector(\"a\")\n                    content = await page.content()\n                    soup = BeautifulSoup(content, \"html.parser\")\n                    urls = soup.select(\"a\")\n\n                    subdirs = []\n                    files = []\n                    for urlElement in urls:\n                        href = urlElement.get(\"href\")\n                        if href.startswith('..'):\n                            continue\n                        elif href.endswith('/'):\n                            subdirName = href.rstrip('/')\n                            subdirs.append(subdirName)\n                        else:\n                            files.append(href)\n\n                    versionSubdirs = []\n                    nonVersionSubdirs = []\n                    for subdir in subdirs:\n                        if isValidVersion(subdir):\n                            try:\n                                parsedVersion = version.parse(subdir)\n                                versionSubdirs.append((parsedVersion, subdir))\n                            except Exception as e:\n                                writeLog(\"exception\", exceptionLogger, f\"Error parsing version: {subdir}, {e}\")\n                                nonVersionSubdirs.append(subdir)\n                        else:\n                            nonVersionSubdirs.append(subdir)\n\n                    if versionSubdirs:\n                        versionSubdirs.sort(reverse=True)\n                        for parsedVersion, versionStr in versionSubdirs:\n                            versionUrl = currentUrl + versionStr + '/'\n                            writeLog(\"info\", logger, f\"Checking version directory: {versionUrl}\")\n                            await page.goto(versionUrl)\n                            await page.wait_for_selector(\"a\")\n                            versionContent = await page.content()\n                            versionSoup = BeautifulSoup(versionContent, \"html.parser\")\n                            versionUrls = versionSoup.select(\"a\")\n                            for urlElement in versionUrls:\n                                href = urlElement.get(\"href\")\n                                if href.startswith('..'):\n                                    continue\n                                elif href and re.search(r\"\\.(jar|aar)$\", href):\n                                    if isTplFile(href):\n                                        jarFileUrl = versionUrl + href\n                                        jarFilesUrls.append(jarFileUrl)\n                                        break\n                            else:\n                                continue\n                            break\n\n                    for subdirName in nonVersionSubdirs:\n                        updatedDirectoryUrl = currentUrl + subdirName + '/'\n                        queue.append(updatedDirectoryUrl)\n\n                except Exception as e:\n                    writeLog(\"exception\", exceptionLogger, f\"Error while traversing: {currentUrl}, {e}\")\n                finally:\n                    await page.close()\n        await browser.close()\n    return jarFilesUrls\n</code></pre>"},{"location":"dataCollectors/utils.html","title":"utils","text":""},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.getExpandedHtml","title":"<code>getExpandedHtml(url)</code>","text":"<p>Fetches the fully rendered HTML content of a webpage by simulating a real browser.</p> <p>This function uses Playwright to launch a headless Chromium browser, navigates to the specified URL, performs scrolling to load dynamic content, and returns the rendered HTML.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the webpage to retrieve.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The rendered HTML content of the page as a string.</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def getExpandedHtml(url):\n    \"\"\"\n    Fetches the fully rendered HTML content of a webpage by simulating a real browser.\n\n    This function uses Playwright to launch a headless Chromium browser, navigates to the specified URL,\n    performs scrolling to load dynamic content, and returns the rendered HTML.\n\n    :param url: The URL of the webpage to retrieve.\n    :type url: str\n    :return: The rendered HTML content of the page as a string.\n    :rtype: str\n    \"\"\"\n    with sync_playwright() as p:\n        browser = p.chromium.launch(\n            headless=True,\n            args=[\n                \"--no-sandbox\",\n                \"--disable-setuid-sandbox\",\n                \"--disable-blink-features=AutomationControlled\"\n            ]\n        )\n        context = browser.new_context(\n            viewport={'width': 1920, 'height': 1080},\n            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n                       'AppleWebKit/537.36 (KHTML, like Gecko) '\n                       'Chrome/112.0.0.0 Safari/537.36'\n        )\n\n        page = context.new_page()\n        page.goto(url)\n        scrollDownAndLoad(page)\n\n        page.wait_for_timeout(5000)\n        html = BeautifulSoup(page.content(), 'html.parser')\n        browser.close()\n\n        return str(html)\n</code></pre>"},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.getHrefs","title":"<code>getHrefs(url)</code>","text":"<p>Retrieves all href attributes from anchor tags on the specified webpage.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the webpage to scrape.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of href links found on the page.</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def getHrefs(url):\n    \"\"\"\n    Retrieves all href attributes from anchor tags on the specified webpage.\n\n    :param url: The URL of the webpage to scrape.\n    :type url: str\n    :return: A list of href links found on the page.\n    :rtype: list[str]\n    \"\"\"\n    html = getExpandedHtml(url)\n    soup = BeautifulSoup(html, 'html.parser')\n\n    hrefs = []\n\n    for link in soup.find_all('a', href=True):\n        hrefs.append(link['href'])\n\n    return hrefs\n</code></pre>"},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.getPathUrlsAppbrain","title":"<code>getPathUrlsAppbrain(url)</code>","text":"<p>Extracts unique path URLs from the AppBrain page for a given application category.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the AppBrain category page to scrape.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of unique path URLs extracted from the page.</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def getPathUrlsAppbrain(url):\n    \"\"\"\n    Extracts unique path URLs from the AppBrain page for a given application category.\n\n    :param url: The URL of the AppBrain category page to scrape.\n    :type url: str\n    :return: A list of unique path URLs extracted from the page.\n    :rtype: list[str]\n    \"\"\"\n    html = getExpandedHtml(url)\n    soup = BeautifulSoup(html, 'html.parser')\n\n    pathUrls = []\n\n    for wideContent in soup.find_all(class_=\"wide-content\"):\n        for link in wideContent.find_all('a', href=True):\n            pathUrls.append(link['href'])\n\n    pathUrls = list(set(pathUrls))\n\n    return pathUrls\n</code></pre>"},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.reorderListId","title":"<code>reorderListId(list)</code>","text":"<p>Reorders a list of dictionaries by converting ObjectId instances to strings and ensuring '_id' is the first key.</p> <p>Parameters:</p> Name Type Description Default <code>list</code> <code>list[dict]</code> <p>The list of dictionaries to reorder.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>A new list with reordered dictionaries.</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def reorderListId(list):\n    \"\"\"\n    Reorders a list of dictionaries by converting ObjectId instances to strings and ensuring '_id' is the first key.\n\n    :param list: The list of dictionaries to reorder.\n    :type list: list[dict]\n    :return: A new list with reordered dictionaries.\n    :rtype: list[dict]\n    \"\"\"\n    reorderedHostAppsList = []\n\n    for element in list:\n\n        if isinstance(element.get(\"_id\"), ObjectId):\n            element[\"_id\"] = str(element[\"_id\"])\n\n        reorderedHostApp = {\"_id\": element[\"_id\"]}\n        reorderedHostApp.update(\n            {fieldName: fieldValue for fieldName, fieldValue in element.items() if fieldName != \"_id\"})\n        reorderedHostAppsList.append(reorderedHostApp)\n    return reorderedHostAppsList\n</code></pre>"},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.scrollDownAndLoad","title":"<code>scrollDownAndLoad(page, scrollPauseTime=1.0, maxScrolls=50)</code>","text":"<p>Scrolls down the webpage incrementally to load dynamic content.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>playwright.sync_api.Page</code> <p>The Playwright page object to interact with.</p> required <code>scrollPauseTime</code> <code>float</code> <p>Time to wait after each scroll, in seconds. Defaults to 1.0.</p> <code>1.0</code> <code>maxScrolls</code> <code>int</code> <p>Maximum number of scroll actions to perform. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def scrollDownAndLoad(page, scrollPauseTime=1.0, maxScrolls=50):\n    \"\"\"\n   Scrolls down the webpage incrementally to load dynamic content.\n\n   :param page: The Playwright page object to interact with.\n   :type page: playwright.sync_api.Page\n   :param scrollPauseTime: Time to wait after each scroll, in seconds. Defaults to 1.0.\n   :type scrollPauseTime: float\n   :param maxScrolls: Maximum number of scroll actions to perform. Defaults to 50.\n   :type maxScrolls: int\n   :return: None\n   :rtype: None\n   \"\"\"\n    lastHeight = page.evaluate(\"document.body.scrollHeight\")\n\n    for _ in range(maxScrolls):\n        page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n        time.sleep(scrollPauseTime)\n\n        newHeight = page.evaluate(\"document.body.scrollHeight\")\n\n        if newHeight == lastHeight:\n            break\n        lastHeight = newHeight\n</code></pre>"},{"location":"dataCollectors/utils.html#sources.dataCollectors.utils.scrollUpUntilVisible","title":"<code>scrollUpUntilVisible(page, selector)</code>","text":"<p>Scrolls up the webpage incrementally until the specified element becomes visible.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>playwright.sync_api.Page</code> <p>The Playwright page object to interact with.</p> required <code>selector</code> <code>str</code> <p>The CSS selector of the element to make visible.</p> required <p>Returns:</p> Type Description <code>playwright.sync_api.ElementHandle</code> <p>The Playwright element handle if found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element with the specified selector is not visible after scrolling.</p> Source code in <code>sources/dataCollectors/utils.py</code> <pre><code>def scrollUpUntilVisible(page, selector):\n    \"\"\"\n    Scrolls up the webpage incrementally until the specified element becomes visible.\n\n    :param page: The Playwright page object to interact with.\n    :type page: playwright.sync_api.Page\n    :param selector: The CSS selector of the element to make visible.\n    :type selector: str\n    :return: The Playwright element handle if found.\n    :rtype: playwright.sync_api.ElementHandle\n    :raises Exception: If the element with the specified selector is not visible after scrolling.\n    \"\"\"\n    element = None\n\n    while True:\n        try:\n            element = page.wait_for_selector(selector, timeout=2000, state='visible')\n            if element:\n                break\n        except Exception:\n            pass\n\n        previousScrollPosition = page.evaluate(\"window.scrollY\")\n\n        page.evaluate(\"window.scrollBy(0, -10)\")\n        page.wait_for_timeout(1000)\n\n        currentScrollPosition = page.evaluate(\"window.scrollY\")\n\n        if currentScrollPosition == previousScrollPosition:\n            break\n\n    if not element:\n        raise Exception(f'The element with selector {selector} was not visible.')\n\n    return element\n</code></pre>"},{"location":"downloaders/getHostApks.html","title":"getHostApks.md","text":""},{"location":"downloaders/getHostApks.html#sources.downloaders.getHostApks.main","title":"<code>main()</code>","text":"<p>Main function to orchestrate the APK download process.</p> Source code in <code>sources/downloaders/getHostApks.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to orchestrate the APK download process.\n    \"\"\"\n    client = MongoClient('mongodb://10.201.54.162:49016')\n    db = client['metadata']\n    apksCollection = db['apks']\n\n    logFilePath = \"../logs/apk.log\"\n    exceptionLogFilePath = \"../logs/apkException.log\"\n\n    configureLogger(logFilePath, \"w\", \"logger\")\n    configureLogger(exceptionLogFilePath, \"w\", \"exceptionLogger\")\n\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    nfsSaveFolder = \"/home/dblancoaza/SafeMountain/nfs/incibePro/analisisAplicaciones/datasets/hostApks/\"\n    checkFolder(nfsSaveFolder)\n\n    batchLimit = 5\n    downloadCount = 0\n\n    with client.start_session() as session:\n        lastDownloadTryDate = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n\n        documents = apksCollection.find(\n            {\n                \"lastDownloadTryDate\": {\"$ne\": lastDownloadTryDate}\n            },\n            no_cursor_timeout=True,\n            session=session\n        ).batch_size(5)\n\n        try:\n            for document in documents:\n                if downloadCount &gt;= batchLimit:\n                    break\n\n                downloadCount = processDocument(\n                    document,\n                    apksCollection,\n                    logger,\n                    exceptionLogger,\n                    nfsSaveFolder,\n                    lastDownloadTryDate,\n                    batchLimit,\n                    downloadCount\n                )\n        finally:\n            documents.close()\n</code></pre>"},{"location":"downloaders/getHostApks.html#sources.downloaders.getHostApks.processDocument","title":"<code>processDocument(document, apksCollection, logger, exceptionLogger, nfsSaveFolder, lastDownloadTryDate, batchLimit, downloadCount)</code>","text":"<p>Processes a single APK document by downloading the APK, updating the MongoDB collection, and updating the corresponding JSON file.</p> <p>This function handles downloading the APK, updating the download status in the MongoDB collection, and updating the related JSON file with the latest download information.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>dict</code> <p>The MongoDB document containing APK details.</p> required <code>apksCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for APKs.</p> required <code>logger</code> <code>logging.Logger</code> <p>Logger for general logging.</p> required <code>exceptionLogger</code> <code>logging.Logger</code> <p>Logger for exception logging.</p> required <code>nfsSaveFolder</code> <code>str</code> <p>The base directory path where APKs should be saved.</p> required <code>lastDownloadTryDate</code> <code>str</code> <p>The current date in UTC formatted as YYYYMMDD.</p> required <code>batchLimit</code> <code>int</code> <p>The maximum number of APKs to download in this batch.</p> required <code>downloadCount</code> <code>int</code> <p>The current count of downloaded APKs.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Updated download count after processing the document.</p> Source code in <code>sources/downloaders/getHostApks.py</code> <pre><code>def processDocument(document, apksCollection, logger, exceptionLogger, nfsSaveFolder, lastDownloadTryDate, batchLimit,\n                     downloadCount):\n    \"\"\"\n    Processes a single APK document by downloading the APK, updating the MongoDB collection, and updating the corresponding JSON file.\n\n    This function handles downloading the APK, updating the download status in the MongoDB collection,\n    and updating the related JSON file with the latest download information.\n\n    :param document: The MongoDB document containing APK details.\n    :type document: dict\n    :param apksCollection: The MongoDB collection for APKs.\n    :type apksCollection: pymongo.collection.Collection\n    :param logger: Logger for general logging.\n    :type logger: logging.Logger\n    :param exceptionLogger: Logger for exception logging.\n    :type exceptionLogger: logging.Logger\n    :param nfsSaveFolder: The base directory path where APKs should be saved.\n    :type nfsSaveFolder: str\n    :param lastDownloadTryDate: The current date in UTC formatted as YYYYMMDD.\n    :type lastDownloadTryDate: str\n    :param batchLimit: The maximum number of APKs to download in this batch.\n    :type batchLimit: int\n    :param downloadCount: The current count of downloaded APKs.\n    :type downloadCount: int\n    :return: Updated download count after processing the document.\n    :rtype: int\n    \"\"\"\n    if downloadCount &gt;= batchLimit:\n        return downloadCount\n\n    try:\n        category = document.get('category')\n        categorySaveFolder = os.path.join(nfsSaveFolder, category)\n        checkFolder(categorySaveFolder)\n\n        hostAppName = document.get('name')\n        hostAppPackage = document.get('package')\n\n        apkSaveFolder = os.path.join(categorySaveFolder, hostAppPackage)\n        checkFolder(apkSaveFolder)\n\n        downloadUrl = f'https://apkpure.com/es/{hostAppName}/{hostAppPackage}/download'\n        writeLog(\"debug\", logger, \"Downloading APK from: \" + downloadUrl)\n\n        downloadedVersion = downloadHostApk(downloadUrl, hostAppName, apkSaveFolder)\n\n        downloadDate = None\n\n        if downloadedVersion != document.get('downloadedVersion') and downloadedVersion != \"Unknown\":\n            downloadDate = lastDownloadTryDate\n\n            apksCollection.update_one(\n                {\"_id\": document[\"_id\"]},\n                {\"$set\": {\"downloadDate\": downloadDate, \"lastDownloadTryDate\": lastDownloadTryDate,\n                          \"downloadedVersion\": downloadedVersion}},\n            )\n        else:\n            apksCollection.update_one(\n                {\"_id\": document[\"_id\"]},\n                {\"$set\": {\"lastDownloadTryDate\": lastDownloadTryDate}},\n            )\n\n        jsonFilePath = os.path.join(\"../../results/hostAppsList/\", f\"{category}.json\")\n        if os.path.exists(jsonFilePath):\n            with open(jsonFilePath, \"r+\", encoding=\"utf-8\") as jsonFile:\n                try:\n                    apks = json.load(jsonFile)\n                except json.JSONDecodeError as e:\n                    writeLog(\"exception\", exceptionLogger, f\"Error decoding the JSON file {category}.json: \\n{e}\")\n                    apks = []\n\n                for apk in apks:\n                    if apk.get(\"_id\") == str(document[\"_id\"]):\n                        apk[\"lastDownloadTryDate\"] = lastDownloadTryDate\n                        if downloadDate:\n                            apk[\"downloadDate\"] = downloadDate\n                        apk[\"downloadedVersion\"] = downloadedVersion\n                        break\n\n                jsonFile.seek(0)\n                json.dump(apks, jsonFile, ensure_ascii=False, indent=4)\n                jsonFile.truncate()\n\n        downloadCount += 1\n\n    except Exception as e:\n        hostAppName = document.get('name')\n        hostAppPackage = document.get('package')\n        writeLog(\"error\", exceptionLogger,\n                 f\"Error downloading APK {hostAppName} ({hostAppPackage}) from {downloadUrl}: {str(e)}\")\n\n    return downloadCount\n</code></pre>"},{"location":"downloaders/getTpls.html","title":"getTpls","text":""},{"location":"downloaders/getTpls.html#sources.downloaders.getTpls.downloadTpl","title":"<code>downloadTpl(versionDoc, tplSaveFolder, semaphore, versionsCollection, maxRetries=3)</code>  <code>async</code>","text":"<p>Asynchronously downloads a Template (TPL) file from a specified URL and saves it to the designated folder.</p> <p>The function attempts to download the TPL file up to <code>maxRetries</code> times in case of failures such as timeouts or client errors. Upon successful download, it updates the <code>lastTimeChecked</code> field in the corresponding version document in the MongoDB collection.</p> <p>Parameters:</p> Name Type Description Default <code>versionDoc</code> <code>dict</code> <p>The MongoDB document containing version details, including the download URL and version code.</p> required <code>tplSaveFolder</code> <code>str</code> <p>The directory path where the downloaded TPL files should be saved.</p> required <code>semaphore</code> <code>asyncio.Semaphore</code> <p>An asyncio semaphore to limit the number of concurrent download operations.</p> required <code>versionsCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for storing version documents.</p> required <code>maxRetries</code> <code>int</code> <p>The maximum number of retry attempts for downloading the TPL file. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>sources/downloaders/getTpls.py</code> <pre><code>async def downloadTpl(versionDoc, tplSaveFolder, semaphore, versionsCollection, maxRetries=3):\n    \"\"\"\n    Asynchronously downloads a Template (TPL) file from a specified URL and saves it to the designated folder.\n\n    The function attempts to download the TPL file up to `maxRetries` times in case of failures such as timeouts\n    or client errors. Upon successful download, it updates the `lastTimeChecked` field in the corresponding\n    version document in the MongoDB collection.\n\n    :param versionDoc: The MongoDB document containing version details, including the download URL and version code.\n    :type versionDoc: dict\n    :param tplSaveFolder: The directory path where the downloaded TPL files should be saved.\n    :type tplSaveFolder: str\n    :param semaphore: An asyncio semaphore to limit the number of concurrent download operations.\n    :type semaphore: asyncio.Semaphore\n    :param versionsCollection: The MongoDB collection for storing version documents.\n    :type versionsCollection: pymongo.collection.Collection\n    :param maxRetries: The maximum number of retry attempts for downloading the TPL file. Defaults to 3.\n    :type maxRetries: int\n    :return: None\n    :rtype: None\n    \"\"\"\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    retries = 0\n    while retries &lt; maxRetries:\n        async with semaphore:\n            try:\n                downloadUrl = versionDoc[\"downloadUrl\"]\n                versionCode = versionDoc[\"versionCode\"]\n\n                timeout = aiohttp.ClientTimeout(total=300)\n\n                async with aiohttp.ClientSession(timeout=timeout) as session:\n                    async with session.get(downloadUrl) as response:\n                        if response.status == 200:\n                            contentDisposition = response.headers.get('Content-Disposition', '')\n                            if 'filename=' in contentDisposition:\n                                suggestedFilename = contentDisposition.split('filename=')[-1].strip('\"')\n                            else:\n                                suggestedFilename = os.path.basename(downloadUrl)\n                            _, extension = os.path.splitext(suggestedFilename)\n                            extension = extension[1:]\n                            checkFolder(tplSaveFolder)\n                            savePath = os.path.join(tplSaveFolder, f\"{versionCode}.{extension}\")\n\n                            chunkSize = 65536  # 64 KB\n                            with open(savePath, 'wb') as f:\n                                async for chunk in response.content.iter_chunked(chunkSize):\n                                    if chunk:\n                                        f.write(chunk)\n                            writeLog(\"debug\", logger, f'TPL successfully downloaded: {savePath}')\n\n                            currentTime = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n                            versionsCollection.update_one(\n                                {\"_id\": versionDoc[\"_id\"]},\n                                {\"$set\": {\"lastTimeChecked\": currentTime}}\n                            )\n                            return\n                        else:\n                            writeLog(\"error\", exceptionLogger,\n                                     f'Failed to download TPL from {downloadUrl} with status code {response.status}')\n                            break\n            except (asyncio.TimeoutError, aiohttp.ClientError) as e:\n                retries += 1\n                writeLog(\"error\", exceptionLogger,\n                         f'Error while downloading {downloadUrl}, retry {retries}/{maxRetries}: {e}')\n                await asyncio.sleep(2)\n            except Exception as e:\n                writeLog(\"error\", exceptionLogger, f'Unexpected error in downloadTpl: {e}')\n                break\n    writeLog(\"error\", exceptionLogger,\n             f'Failed to download TPL from {downloadUrl} after {maxRetries} retries')\n</code></pre>"},{"location":"downloaders/getTpls.html#sources.downloaders.getTpls.main","title":"<code>main()</code>  <code>async</code>","text":"<p>The main asynchronous function orchestrating the download of TPL files.</p> Source code in <code>sources/downloaders/getTpls.py</code> <pre><code>async def main():\n    \"\"\"\n    The main asynchronous function orchestrating the download of TPL files.\n    \"\"\"\n    client = MongoClient('mongodb://10.201.54.162:49016')\n    db = client['metadata']\n    tplsCollection = db['tpls']\n    versionsCollection = db['versions']\n\n    logFilePath = \"../logs/tpl.log\"\n    exceptionLogFilePath = \"../logs/tplException.log\"\n\n    configureLogger(logFilePath, \"a\", \"logger\")\n    configureLogger(exceptionLogFilePath, \"a\", \"exceptionLogger\")\n\n    logger = logging.getLogger(\"logger\")\n    exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n    nfsSaveFolder = \"/home/dblancoaza/SafeMountain/nfs/incibePro/analisisAplicaciones/datasets/tpls/\"\n    checkFolder(nfsSaveFolder)\n\n    semaphore = asyncio.Semaphore(3)\n\n    queue = asyncio.Queue()\n\n    docsToProcess = versionsCollection.find(\n        {\"type\": \"tpl\", \"lastTimeChecked\": {\"$exists\": False}}\n    ).limit(100)\n\n    docsList = list(docsToProcess)\n    if not docsList:\n        writeLog(\"info\", logger, \"No TPL versions without lastTimeChecked to download.\")\n        return\n\n    for versionDoc in docsList:\n        parentId = versionDoc.get(\"parentId\")\n        if not parentId:\n            writeLog(\"error\", exceptionLogger, f'Missing parentId in versionDoc {versionDoc.get(\"_id\")}')\n            continue\n\n        if not isinstance(parentId, ObjectId):\n            parentId = ObjectId(parentId)\n\n        tplDoc = tplsCollection.find_one({\"_id\": parentId})\n        if not tplDoc:\n            writeLog(\"error\", exceptionLogger,\n                     f'No TPL document found for parentId {parentId} in versionDoc {versionDoc.get(\"_id\")}')\n            continue\n\n        package = tplDoc.get(\"package\")\n        name = tplDoc.get(\"name\")\n        if package and name:\n            versionDoc['package'] = package\n            versionDoc['name'] = name\n\n            packageParts = package.split('.')\n\n            packageSaveFolder = os.path.join(nfsSaveFolder, *packageParts)\n            checkFolder(packageSaveFolder)\n\n            tplSaveFolder = os.path.join(packageSaveFolder, name)\n            checkFolder(tplSaveFolder)\n\n            await queue.put({'versionDoc': versionDoc, 'tplSaveFolder': tplSaveFolder})\n        else:\n            writeLog(\"error\", exceptionLogger,\n                     f'Missing package or name in tplDoc for versionDoc {versionDoc.get(\"_id\")}')\n\n    if queue.empty():\n        writeLog(\"info\", logger, \"No TPL versions with package and name to download.\")\n        return\n\n    numWorkers = 3\n    workerTasks = []\n    for _ in range(numWorkers):\n        task = asyncio.create_task(worker(queue, semaphore, versionsCollection))\n        workerTasks.append(task)\n\n    await queue.join()\n\n    for _ in range(numWorkers):\n        await queue.put(None)\n\n    await asyncio.gather(*workerTasks)\n</code></pre>"},{"location":"downloaders/getTpls.html#sources.downloaders.getTpls.worker","title":"<code>worker(queue, semaphore, versionsCollection)</code>  <code>async</code>","text":"<p>Asynchronous worker that continuously processes items from the queue to download TPL files.</p> <p>Each worker retrieves an item from the queue, which contains the version document and the folder where the TPL should be saved, and invokes the <code>downloadTpl</code> function to perform the download.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>asyncio.Queue</code> <p>An asyncio queue containing items to be processed, where each item is a dictionary with keys 'versionDoc' and 'tplSaveFolder'.</p> required <code>semaphore</code> <code>asyncio.Semaphore</code> <p>An asyncio semaphore to limit the number of concurrent download operations.</p> required <code>versionsCollection</code> <code>pymongo.collection.Collection</code> <p>The MongoDB collection for storing version documents.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>sources/downloaders/getTpls.py</code> <pre><code>async def worker(queue, semaphore, versionsCollection):\n    \"\"\"\n    Asynchronous worker that continuously processes items from the queue to download TPL files.\n\n    Each worker retrieves an item from the queue, which contains the version document and the folder\n    where the TPL should be saved, and invokes the `downloadTpl` function to perform the download.\n\n    :param queue: An asyncio queue containing items to be processed, where each item is a dictionary with keys\n                  'versionDoc' and 'tplSaveFolder'.\n    :type queue: asyncio.Queue\n    :param semaphore: An asyncio semaphore to limit the number of concurrent download operations.\n    :type semaphore: asyncio.Semaphore\n    :param versionsCollection: The MongoDB collection for storing version documents.\n    :type versionsCollection: pymongo.collection.Collection\n    :return: None\n    :rtype: None\n    \"\"\"\n    while True:\n        item = await queue.get()\n        if item is None:\n            break\n        await downloadTpl(item['versionDoc'], item['tplSaveFolder'], semaphore, versionsCollection)\n        queue.task_done()\n</code></pre>"},{"location":"downloaders/utils.html","title":"utils","text":""},{"location":"downloaders/utils.html#sources.downloaders.utils.downloadHostApk","title":"<code>downloadHostApk(downloadUrl, hostAppName, apkSaveFolder)</code>","text":"<p>Downloads an APK file for a host application from the specified download URL and saves it to the designated folder.</p> <p>Parameters:</p> Name Type Description Default <code>downloadUrl</code> <code>str</code> <p>The URL from which to download the APK.</p> required <code>hostAppName</code> <code>str</code> <p>The name of the host application, used to name the downloaded APK file.</p> required <code>apkSaveFolder</code> <code>str</code> <p>The directory path where the downloaded APK should be saved.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>The version of the downloaded APK if successful; otherwise, <code>None</code>.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the download link is not found or an unexpected error occurs during the download process.</p> Source code in <code>sources/downloaders/utils.py</code> <pre><code>def downloadHostApk(downloadUrl, hostAppName, apkSaveFolder):\n    \"\"\"\n    Downloads an APK file for a host application from the specified download URL and saves it to the designated folder.\n\n    :param downloadUrl: The URL from which to download the APK.\n    :type downloadUrl: str\n    :param hostAppName: The name of the host application, used to name the downloaded APK file.\n    :type hostAppName: str\n    :param apkSaveFolder: The directory path where the downloaded APK should be saved.\n    :type apkSaveFolder: str\n    :return: The version of the downloaded APK if successful; otherwise, `None`.\n    :rtype: str or None\n    :raises Exception: If the download link is not found or an unexpected error occurs during the download process.\n    \"\"\"\n    with sync_playwright() as p:\n        try:\n            logger = logging.getLogger(\"logger\")\n            exceptionLogger = logging.getLogger(\"exceptionLogger\")\n\n            browser = p.chromium.launch(\n                headless=True,\n                args=[\n                    \"--no-sandbox\",\n                    \"--disable-setuid-sandbox\",\n                    \"--disable-blink-features=AutomationControlled\",\n                    \"--window-size=1920,1080\",\n                    \"--start-maximized\"\n                ]\n            )\n            context = browser.new_context(\n                viewport={'width': 1920, 'height': 1080},\n                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n                           'AppleWebKit/537.36 (KHTML, like Gecko) '\n                           'Chrome/112.0.0.0 Safari/537.36',\n                locale='en-US',\n                timezone_id='America/New_York',\n                permissions=['geolocation'],\n            )\n\n            context.add_init_script(\"\"\"\n                Object.defineProperty(navigator, 'webdriver', {\n                    get: () =&gt; undefined\n                });\n\n                window.navigator.chrome = {\n                    runtime: {},\n                };\n\n                Object.defineProperty(navigator, 'plugins', {\n                    get: () =&gt; [1, 2, 3, 4, 5],\n                });\n\n                Object.defineProperty(navigator, 'languages', {\n                    get: () =&gt; ['en-US', 'en'],\n                });\n            \"\"\")\n\n            page = context.new_page()\n            page.goto(downloadUrl, wait_until='networkidle')\n            page.wait_for_timeout(2000)\n\n            try:\n                accept_button = page.query_selector('button.fc-primary-button')  # Example selector\n                if accept_button:\n                    accept_button.click()\n                    writeLog(\"debug\", logger, \"Clicked the accept button on consent dialog.\")\n                    page.wait_for_timeout(1000)  # Wait a bit after clicking\n            except Exception as e:\n                writeLog(\"debug\", logger, f\"No consent dialog to handle: {e}\")\n\n            try:\n                infoSdkDiv = page.query_selector('span.info-sdk')\n                if infoSdkDiv:\n                    versionSpan = infoSdkDiv.query_selector('span')\n                    downloadedVersion = versionSpan.inner_text().strip() if versionSpan else \"Unknown\"\n                else:\n                    downloadedVersion = \"Unknown\"\n            except Exception as e:\n                writeLog(\"exception\", exceptionLogger, f\"Error extracting version from {downloadUrl}: {str(e)}\")\n                downloadedVersion = \"Unknown\"\n\n            downloadButton = page.query_selector('a.download-btn')\n\n            if not downloadButton:\n                page.screenshot(path=os.path.join(apkSaveFolder, f\"{hostAppName}_no_download_button.png\"), full_page=True)\n                raise Exception(f'Error downloading from: {downloadUrl}')\n\n            with page.expect_download(timeout=60000) as download_info:\n                try:\n                    downloadButton.click()\n                except Exception as e:\n                    writeLog(\"exception\", exceptionLogger, f\"Error clicking download button: {str(e)}\")\n                    page.screenshot(path=os.path.join(apkSaveFolder, f\"{hostAppName}_click_error.png\"), full_page=True)\n                    raise e\n\n            try:\n                downloadedApk = download_info.value\n            except PlaywrightTimeoutError:\n                writeLog(\"exception\", exceptionLogger, f'Timeout while waiting for download from {downloadUrl}')\n                page.screenshot(path=os.path.join(apkSaveFolder, f\"{hostAppName}_download_timeout.png\"), full_page=True)\n                context.close()\n                browser.close()\n                return None\n\n            if downloadedApk:\n\n                savePath = os.path.join(apkSaveFolder, f\"{hostAppName}.apk\")\n\n                downloadedApk.save_as(savePath)\n                writeLog(\"debug\", logger, f'APK successfully downloaded: {savePath}')\n\n                context.close()\n                browser.close()\n\n                return downloadedVersion\n            else:\n                page.screenshot(path=os.path.join(apkSaveFolder, f\"{hostAppName}_download_failed.png\"), full_page=True)\n                writeLog(\"exception\", exceptionLogger, f'Failed to download APK from {downloadUrl}')\n                context.close()\n                browser.close()\n                return None\n\n        except Exception as e:\n            if 'page' in locals():\n                page.screenshot(path=os.path.join(apkSaveFolder, f\"{hostAppName}_unexpected_error.png\"), full_page=True)\n            writeLog(\"exception\", exceptionLogger, f'Unexpected error in downloadHostApk: {e}')\n            return None\n</code></pre>"}]}